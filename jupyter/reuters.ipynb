{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters - Multi Class Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words= 10000)\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      " [1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12]\n",
      " [1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12]\n",
      " ...,\n",
      " [1, 141, 3890, 387, 81, 8, 16, 1629, 10, 340, 1241, 850, 31, 56, 3890, 691, 9, 1241, 71, 9, 5985, 2, 2, 699, 2, 2, 2, 699, 244, 5945, 4, 49, 8, 4, 656, 850, 33, 2993, 9, 2139, 340, 3371, 1493, 9, 2, 22, 2, 1094, 687, 83, 35, 15, 257, 6, 57, 9190, 7, 4, 5956, 654, 5, 2, 6191, 1371, 4, 49, 8, 16, 369, 646, 6, 1076, 7, 124, 407, 17, 12]\n",
      " [1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 3614, 18, 14, 74, 134, 5131, 18, 88, 2321, 72, 11, 14, 1842, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 3237, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 1072, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 1172, 137, 336, 1325, 6, 1532, 142, 971, 6463, 43, 359, 5, 4, 326, 753, 364, 17, 12]\n",
      " [1, 227, 2406, 91, 2, 125, 2855, 21, 4, 3976, 76, 7, 4, 757, 481, 3976, 790, 5259, 5654, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 1047, 91, 6917, 1688, 340, 7, 194, 9411, 6, 1894, 21, 127, 2151, 2394, 1456, 6, 3034, 4, 329, 433, 7, 65, 87, 1127, 10, 8219, 1475, 290, 9, 21, 567, 16, 1926, 24, 4, 76, 209, 30, 4033, 6655, 5654, 8, 4, 60, 8, 4, 966, 308, 40, 2575, 129, 2, 295, 277, 1071, 9, 24, 286, 2114, 234, 222, 9, 4, 906, 3994, 8519, 114, 5758, 1752, 7, 4, 113, 17, 12]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  1. ...,  0.  0.  0.]\n",
      " [ 0.  1.  1. ...,  0.  0.  0.]\n",
      " [ 0.  1.  1. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  1. ...,  0.  0.  0.]\n",
      " [ 0.  1.  1. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    \n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)\n",
    "\n",
    "print(one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s - loss: 2.5306 - acc: 0.4962 - val_loss: 1.7180 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s - loss: 1.4430 - acc: 0.6878 - val_loss: 1.3435 - val_acc: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s - loss: 1.0929 - acc: 0.7661 - val_loss: 1.1704 - val_acc: 0.7430\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.8682 - acc: 0.8166 - val_loss: 1.0788 - val_acc: 0.7600\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.7020 - acc: 0.8483 - val_loss: 0.9844 - val_acc: 0.7830\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.5666 - acc: 0.8796 - val_loss: 0.9401 - val_acc: 0.8030\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.4592 - acc: 0.9039 - val_loss: 0.9090 - val_acc: 0.8000\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.3703 - acc: 0.9226 - val_loss: 0.9349 - val_acc: 0.7880\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.3036 - acc: 0.9308 - val_loss: 0.8913 - val_acc: 0.8070\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.2539 - acc: 0.9414 - val_loss: 0.9055 - val_acc: 0.8110\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.2185 - acc: 0.9471 - val_loss: 0.9168 - val_acc: 0.8120\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.1871 - acc: 0.9511 - val_loss: 0.9036 - val_acc: 0.8140\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.1697 - acc: 0.9523 - val_loss: 0.9339 - val_acc: 0.8090\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.1532 - acc: 0.9551 - val_loss: 0.9652 - val_acc: 0.8080\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.1389 - acc: 0.9558 - val_loss: 0.9708 - val_acc: 0.8120\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.1312 - acc: 0.9564 - val_loss: 1.0290 - val_acc: 0.8020\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.1214 - acc: 0.9574 - val_loss: 1.0285 - val_acc: 0.7970\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.1192 - acc: 0.9575 - val_loss: 1.0460 - val_acc: 0.8070\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.1135 - acc: 0.9594 - val_loss: 1.0989 - val_acc: 0.7970\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s - loss: 0.1104 - acc: 0.9597 - val_loss: 1.0725 - val_acc: 0.8010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b321ae4048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo')\n",
    "plt.plot(epochs, val_loss_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPwNMIL4koEwKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b3221d2fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf() # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "plt.plot(epochs, acc_values, 'bo')\n",
    "plt.plot(epochs, val_acc_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/9\n",
      "8982/8982 [==============================] - 1s - loss: 2.4429 - acc: 0.5332 - val_loss: 1.6603 - val_acc: 0.6469\n",
      "Epoch 2/9\n",
      "8982/8982 [==============================] - 1s - loss: 1.3238 - acc: 0.7160 - val_loss: 1.3112 - val_acc: 0.7039\n",
      "Epoch 3/9\n",
      "8982/8982 [==============================] - 1s - loss: 0.9754 - acc: 0.7866 - val_loss: 1.1430 - val_acc: 0.7511\n",
      "Epoch 4/9\n",
      "8982/8982 [==============================] - 1s - loss: 0.7577 - acc: 0.8395 - val_loss: 1.0419 - val_acc: 0.7658\n",
      "Epoch 5/9\n",
      "8982/8982 [==============================] - 1s - loss: 0.5967 - acc: 0.8770 - val_loss: 0.9859 - val_acc: 0.7778\n",
      "Epoch 6/9\n",
      "8982/8982 [==============================] - 1s - loss: 0.4747 - acc: 0.9007 - val_loss: 0.9759 - val_acc: 0.7881\n",
      "Epoch 7/9\n",
      "8982/8982 [==============================] - 1s - loss: 0.3828 - acc: 0.9178 - val_loss: 0.9552 - val_acc: 0.7925\n",
      "Epoch 8/9\n",
      "8982/8982 [==============================] - 1s - loss: 0.3074 - acc: 0.9351 - val_loss: 0.9640 - val_acc: 0.7979\n",
      "Epoch 9/9\n",
      "8982/8982 [==============================] - 1s - loss: 0.2588 - acc: 0.9413 - val_loss: 0.9806 - val_acc: 0.7916\n",
      "2240/2246 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,\n",
    "    one_hot_train_labels,\n",
    "    epochs=9,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_test, one_hot_test_labels))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98057154683480807, 0.79162956372182069]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Conclusion\n",
    "\n",
    "* If you are trying to classify data points between N classes, your network should end with a Dense layer of size N.\n",
    "\n",
    "* In a single-label, multi-class classification problem, your network should end with a softmax activation, so that it will output a probability distribution over the N output classes.\n",
    "\n",
    "* Categorical crossentropy is almost always the loss function you should use for such problems. It minimizes the distance between the probability distributions output by the network, and the true distribution of the targets.\n",
    "\n",
    "* There are two ways to handle labels in multi-class classification:\n",
    "\n",
    ">* encoding the labels via \"categorical encoding\" (also known as \"one-hot encoding\") and using categorical_crossentropy as your loss function.\n",
    "\n",
    ">*  encoding the labels as integers and using the sparse_categorical_crossentropy loss function.\n",
    "\n",
    "* If you need to classify data into N categories, then you should avoid creating information bottlenecks in your network by having intermediate layers that are too small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
